[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Lab 6",
    "section": "",
    "text": "library(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.4     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(tidymodels)\n\n── Attaching packages ────────────────────────────────────── tidymodels 1.3.0 ──\n✔ broom        1.0.7     ✔ rsample      1.2.1\n✔ dials        1.4.0     ✔ tune         1.3.0\n✔ infer        1.0.7     ✔ workflows    1.2.0\n✔ modeldata    1.4.0     ✔ workflowsets 1.1.0\n✔ parsnip      1.3.1     ✔ yardstick    1.3.2\n✔ recipes      1.2.0     \n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ scales::discard() masks purrr::discard()\n✖ dplyr::filter()   masks stats::filter()\n✖ recipes::fixed()  masks stringr::fixed()\n✖ dplyr::lag()      masks stats::lag()\n✖ yardstick::spec() masks readr::spec()\n✖ recipes::step()   masks stats::step()\n\nlibrary(powerjoin)\nlibrary(glue)\nlibrary(vip)\n\n\nAttaching package: 'vip'\n\nThe following object is masked from 'package:utils':\n\n    vi\n\nlibrary(baguette)\nlibrary(ggthemes)\nlibrary(patchwork)\nlibrary(xgboost)\n\n\nAttaching package: 'xgboost'\n\nThe following object is masked from 'package:dplyr':\n\n    slice\n\nlibrary(parsnip)\nlibrary(workflows)\nlibrary(caret)\n\nLoading required package: lattice\n\nAttaching package: 'caret'\n\nThe following objects are masked from 'package:yardstick':\n\n    precision, recall, sensitivity, specificity\n\nThe following object is masked from 'package:purrr':\n\n    lift\n\nlibrary(tune)\nlibrary(kernlab)\n\n\nAttaching package: 'kernlab'\n\nThe following object is masked from 'package:dials':\n\n    buffer\n\nThe following object is masked from 'package:scales':\n\n    alpha\n\nThe following object is masked from 'package:purrr':\n\n    cross\n\nThe following object is masked from 'package:ggplot2':\n\n    alpha"
  },
  {
    "objectID": "index.html#data-splitting",
    "href": "index.html#data-splitting",
    "title": "Lab 6",
    "section": "Data Splitting",
    "text": "Data Splitting\n\nset.seed(142)\n\ncamels_split3 &lt;- initial_split(camels_clean, prop = 0.75)\ncamels_train3 &lt;- training(camels_split3)\ncamels_test3 &lt;- testing(camels_split3)\n\ncamels_cv3 &lt;- vfold_cv(camels_train3, v = 10)"
  },
  {
    "objectID": "index.html#recipe",
    "href": "index.html#recipe",
    "title": "Lab 6",
    "section": "Recipe",
    "text": "Recipe\n\nrec3 &lt;- recipe(logQmean ~ runoff_ratio_log + low_prec_freq, data = camels_train3) %&gt;%\n  step_interact(terms = ~ runoff_ratio_log:low_prec_freq) %&gt;%\n  step_naomit(all_predictors(), all_outcomes())\n# I wanted to use low precipitation frequency and runoff ratio because I felt like they would both have a good relationship with our streamflow mean. Runoff ratio was skewed to the right so I added a log transform but I kept low_prec_freq as is because the distribution looked relatively normal."
  },
  {
    "objectID": "index.html#define-3-models",
    "href": "index.html#define-3-models",
    "title": "Lab 6",
    "section": "Define 3 Models",
    "text": "Define 3 Models\n\nrandf_model &lt;- rand_forest(mtry = 2, trees = 500) %&gt;%\n  set_engine(\"ranger\") %&gt;%\n  set_mode(\"regression\")\n\n\nlinm_model &lt;- linear_reg() %&gt;%\n  set_engine(\"lm\") %&gt;%\n  set_mode(\"regression\")\n\n\nsvm_model &lt;- svm_rbf() %&gt;%\n  set_engine(\"kernlab\") %&gt;%\n  set_mode(\"regression\")"
  },
  {
    "objectID": "index.html#workflow-set",
    "href": "index.html#workflow-set",
    "title": "Lab 6",
    "section": "Workflow Set",
    "text": "Workflow Set\n\nwf_set &lt;- workflow_set(\n  preproc = list(rec3), \n  models = list(randf_model, linm_model, svm_model) \n)\n\nwf_results &lt;- wf_set %&gt;%\n  workflow_map(\"fit_resamples\", resamples = camels_cv3)"
  },
  {
    "objectID": "index.html#evaluation",
    "href": "index.html#evaluation",
    "title": "Lab 6",
    "section": "Evaluation",
    "text": "Evaluation\n\nautoplot(wf_results)\n\n\n\n\n\n\n\nranked_results &lt;- rank_results(wf_results)\nranked_results\n\n# A tibble: 6 × 9\n  wflow_id          .config .metric  mean std_err     n preprocessor model  rank\n  &lt;chr&gt;             &lt;chr&gt;   &lt;chr&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;int&gt; &lt;chr&gt;        &lt;chr&gt; &lt;int&gt;\n1 recipe_rand_fore… Prepro… rmse    0.264 0.00951    10 recipe       rand…     1\n2 recipe_rand_fore… Prepro… rsq     0.952 0.00446    10 recipe       rand…     1\n3 recipe_svm_rbf    Prepro… rmse    0.303 0.0196     10 recipe       svm_…     2\n4 recipe_svm_rbf    Prepro… rsq     0.938 0.00663    10 recipe       svm_…     2\n5 recipe_linear_reg Prepro… rmse    0.426 0.0167     10 recipe       line…     3\n6 recipe_linear_reg Prepro… rsq     0.878 0.00805    10 recipe       line…     3\n\n# It looks like random forest works the best because it performs the best in the department of rmse and rsq."
  },
  {
    "objectID": "index.html#extract-and-evaluate",
    "href": "index.html#extract-and-evaluate",
    "title": "Lab 6",
    "section": "Extract and Evaluate",
    "text": "Extract and Evaluate\n\nrf_workflow &lt;- workflow() %&gt;%\n  add_recipe(rec3) %&gt;%\n  add_model(randf_model)\n\nrf_fit &lt;- rf_workflow %&gt;%\n  fit(data = camels_train3)\n\nrf_predictions &lt;- rf_fit %&gt;%\n  augment(new_data = camels_test3)\n\nggplot(rf_predictions, aes(x = logQmean, y = .pred)) +\n  geom_point(aes(color = abs(logQmean - .pred)), size = 3, alpha = 0.7) +\n  scale_color_viridis_c() +\n  labs(\n    title = \"Observed vs Predicted LogQmean (Random Forest Model)\",\n    x = \"Observed LogQmean\",\n    y = \"Predicted LogQmean\",\n    color = \"Absolute Error\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n# I believe the random forest model is extraordinarily accurate based off of this graph. The points are in a relative straight line and there's not a lot of spread between them."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  }
]